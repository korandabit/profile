---
author: Mark Koranda
categories:
- LLM Chatbots
- Psychic lenses
date: '2024-07-17 00:00:00'
excerpt: Imagine a world where AI has advanced so far that humans are like dogs to
  their robot owners. Were cared for, but our desires are simplified, our freedoms
  limited. Want to go outside? Ask the AI. Hungry? The AI decides what and when you
  eat.
layout: post
tags:
- ai
- control
- identity
- incentive
- power
- pragmatic
- pragmatism
- prevention
- singularity
title: The fear and power of singularity
---




Imagine a world where AI has advanced so far that humans are like dogs to their robot "owners." We're cared for, but our desires are simplified, our freedoms limited. Want to go outside? Ask the AI.

Hungry? The AI decides what and when you eat. This isn't just science fictionâ€”it's a potential future if we don't address the power dynamics of advancing AI. 

The singularity isn't just about superintelligent machines. It's about who controls them. Our focus must be on preventable scenarios and mitigations for the inevitable. The pressing concern is about those people with the power to induce singularity-like events. 

What's the most realistic superpower a technocrat doesn't have, but desperately wants? Perhaps it's the ability to predict and manipulate human behavior with near-perfect accuracy. Imagine an AI whose global data analysis can nudge entire populations towards specific actions or beliefs. In the wrong hands, this becomes a tool of unprecedented control. 

Prevention isn't about passive regulation. It's about active resistance:

Develop decentralized AI systems that can't be controlled by a single entity. 

Create robust, hack-proof personal data protection technologies.

Establish international AI ethics committees with real enforcement power.

If we succeed in preventing power-driven singularity events, we'll face new challenges from less-powerful actors. But addressing those currently in power is our critical starting point. 

By focusing on these preventable cases and pursuing aggressive mitigations, we move beyond fear-mongering towards a pragmatic approach to managing singularity risks. The goal isn't to prevent progress, but to ensure we remain the masters of our fate, not pets in a gilded cage. 

**Acknowledgements. ***This essay was initially drafted by me, with help on revisions by Claude. Claude developed the hypothetical scenario and actions taken in response. Feel free to insert whatever you like in that box if you don't trust it.*